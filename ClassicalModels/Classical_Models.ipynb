{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWMBPG2k2h-9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install PyGSP\n",
    "!pip install tensorboardx\n",
    "!pip install torch\n",
    "!pip install neuralforecast\n",
    "!pip install pytorch-tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5I-494LvIbF"
   },
   "outputs": [],
   "source": [
    "!pip install -U giotto-tda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fObRj0TtdWq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gtda.graphs import KNeighborsGraph\n",
    "import itertools\n",
    "from pytorch_tcn import TCN\n",
    "\n",
    "\n",
    "#import os\n",
    "#import sys\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "\n",
    "from importlib import reload\n",
    "import Model2\n",
    "reload(Model2)\n",
    "import Model3\n",
    "reload(Model3)\n",
    "\n",
    "from utils import GraphRNN_dataset, GraphRNN_DataSampler\n",
    "from Model2 import STGCNChebGraphConv\n",
    "from Model3 import ParametricNetWithPooling\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting training run...\")\n",
    "flow_dataset = \"../data/daily_county2county_2019_01_01.csv\"\n",
    "epi_dataset = \"../data_epi/epidemiology.csv\"\n",
    "epi_dates = [\"2020-06-09\", \"2020-06-10\", \"2020-06-11\", \"2020-06-12\",\n",
    "             \"2020-06-13\", \"2020-06-14\", \"2020-06-15\", \"2020-06-16\",\n",
    "             \"2020-06-17\", \"2020-06-18\", \"2020-06-19\", \"2020-06-20\",\n",
    "             \"2020-06-21\", \"2020-06-22\", \"2020-06-23\", \"2020-06-24\",\n",
    "                \"2020-06-25\", \"2020-06-26\", \"2020-06-27\", \"2020-06-28\",\n",
    "                \"2020-06-29\", \"2020-06-30\", \"2020-07-01\", \"2020-07-02\",\n",
    "                \"2020-07-03\", \"2020-07-04\", \"2020-07-05\", \"2020-07-06\",\n",
    "                \"2020-07-07\", \"2020-07-08\", \"2020-07-09\", \"2020-07-10\",\n",
    "                \"2020-07-11\", \"2020-07-12\", \"2020-07-13\", \"2020-07-14\",\n",
    "                \"2020-07-15\", \"2020-07-16\", \"2020-07-17\", \"2020-07-18\",\n",
    "                \"2020-07-19\", \"2020-07-20\", \"2020-07-21\", \"2020-07-22\",\n",
    "                \"2020-07-23\", \"2020-07-24\", \"2020-07-25\", \"2020-07-26\",\n",
    "                \"2020-07-27\", \"2020-07-28\", \"2020-07-29\", \"2020-07-30\"\n",
    "             ]\n",
    "\n",
    "\n",
    "input_hor = 5\n",
    "pred_hor = 1\n",
    "print(\"Loading data...\")\n",
    "data_set = GraphRNN_dataset(epi_dates = epi_dates,\n",
    "                            flow_dataset = flow_dataset,\n",
    "                            epi_dataset = epi_dataset,\n",
    "                            input_hor=input_hor,\n",
    "                            pred_hor=pred_hor,\n",
    "                            fake_data=False)\n",
    "# data_set.visualize(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# data_sampler = GraphRNN_DataSampler(data_set, input_hor=input_hor, pred_hor=pred_hor)\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=10, pin_memory=True, num_workers=0, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"Data loaded.\")\n",
    "input_edge_weights, input_node_data, target_edge_weights, target_node_data = next(iter(data_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader:\n",
    "    print(len(batch))\n",
    "    print(batch[0].shape)\n",
    "    print(batch[-1].shape)\n",
    "    break\n",
    "for batch in input_node_data:\n",
    "    print(batch.shape)\n",
    "    for input_type in batch:\n",
    "        #print(input_type.shape)\n",
    "        #print(input_type)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, pred_hor, device, n_epochs =10, save=None):\n",
    "    losses = []\n",
    "    parameter_mag = {param_name: [] for param_name, param in model.named_parameters()}\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        batch_num = 0\n",
    "        for i, (input_edge_weights, input_node_data, target_edge_weights, target_node_data) in enumerate(tqdm(data_loader)):\n",
    "            if batch_num==1 and epoch == 1:\n",
    "                prof.step()\n",
    "            for param_name, param in model.named_parameters():\n",
    "                parameter_mag[param_name].append(param.abs().mean().item())\n",
    "            \n",
    "            input_edge_weights = input_edge_weights[i]\n",
    "            input_node_data = input_node_data[i]\n",
    "            target_edge_weights = target_edge_weights[i]\n",
    "            target_node_data = target_node_data[i]\n",
    "            \n",
    "            input_edge_weights = input_edge_weights.to(device)\n",
    "            input_node_data = input_node_data.to(device)\n",
    "            target_edge_weights = target_edge_weights.to(device)\n",
    "            target_node_data = target_node_data.to(device)\n",
    "            # output = model(x_in=input_node_data, edge_weights = input_edge_weights, pred_hor = pred_hor)\n",
    "            print(input_edge_weights.shape)\n",
    "            print(input_node_data.shape)\n",
    "            print(target_edge_weights.shape)\n",
    "            print(target_node_data.shape)\n",
    "            output = model(x=input_node_data)\n",
    "\n",
    "            \n",
    "            # print(f\"output: {output}\")\n",
    "            # print(f\"target_node_data: {target_node_data}\")\n",
    "              \n",
    "            loss = criterion(output[-pred_hor:,:,:], target_node_data[:pred_hor,:,:])\n",
    "            loss += 0 * criterion(output[:input_hor,:,:], input_node_data[:,:])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            batch_num += 1\n",
    "        epoch_loss = epoch_loss/((pred_hor) * target_node_data.shape[2])\n",
    "        losses.append(epoch_loss)\n",
    "        print(f\"EPOCH: {epoch} \", end=\"\")\n",
    "        \n",
    "        print(f\"$ Loss: { epoch_loss:.3e} \")\n",
    "        \n",
    "        print(f\"Input: {input_node_data[:, :5, 0].int()} \")\n",
    "        print(f\"$ Output: {output[-pred_hor:, :5, 0].int()} \")\n",
    "        print(f\"$ Target: {target_node_data[:, :5, 0].int()}\")\n",
    "    if save is not None:\n",
    "        torch.save(model.state_dict(), save)\n",
    "    return losses, parameter_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reimport models\n",
    "import Model2\n",
    "reload(Model2)\n",
    "import Model3\n",
    "reload(Model3)\n",
    "from utils import GraphRNN_dataset, GraphRNN_DataSampler\n",
    "from Model1 import Temporal_Processing\n",
    "from Model2 import STGCNChebGraphConv\n",
    "from Model3 import ParametricNetWithPooling\n",
    "\n",
    "models  = [\n",
    "            TCN(\n",
    "                num_inputs = data_set.n_features,\n",
    "                num_channels = [3070, 1, 4],\n",
    "                kernel_size = 1, #kernel_size: int = 4,\n",
    "                input_shape = 'NLC', #input_shape: str = 'NCL',\n",
    "                lookahead = 7, # default: 0\n",
    "                #dilations: Optional[ ArrayLike ] = None,\n",
    "                #dilation_reset: Optional[ int ] = None,\n",
    "                #dropout: float = 0.1,\n",
    "                #causal: bool = True,\n",
    "                #use_norm: str = 'weight_norm',\n",
    "                #activation: str = 'relu',\n",
    "                #kernel_initializer: str = 'xavier_uniform',\n",
    "                #use_skip_connections: bool = False,\n",
    "                #embedding_shapes: Optional[ ArrayLike ] = None,\n",
    "                #embedding_mode: str = 'add',\n",
    "                #use_gate: bool = False,\n",
    "                #output_projection: Optional[ int ] = None,\n",
    "                #output_activation: Optional[ str ] = None,\n",
    "            ),\n",
    "           # STGCNChebGraphConv(n_nodes = data_set.n_nodes,\n",
    "           #         n_features = data_set.n_features,\n",
    "           #         h_size = 50,\n",
    "           #         f_out_size = 50,\n",
    "           #         fixed_edge_weights = input_edge_weights[0,0,:,:],\n",
    "           #         device=device,\n",
    "           #         dtype=torch.float32),\n",
    "           # ParametricNetWithPooling(n_nodes = data_set.n_nodes,\n",
    "           #         n_features = data_set.n_features,\n",
    "           #         h_size = 50,\n",
    "           #         f_out_size = 50,\n",
    "           #         fixed_edge_weights = input_edge_weights[0,0,:,:],\n",
    "           #         device=device,\n",
    "           #         dtype=torch.float32)\n",
    "]\n",
    "model_output = []\n",
    "\n",
    "# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "for i, model in enumerate(models):\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "    criterion = torch.nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00045)\n",
    "\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    log_dir = './log'\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    # Use torch.profiler to profile the model\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=0),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=False,\n",
    "        with_stack=True\n",
    "    ) as prof:\n",
    "        print(\"Starting training with profiling...\")\n",
    "        losses, parameter_mag = train(model, data_loader,\n",
    "                                  criterion, optimizer,\n",
    "                                  pred_hor, device, n_epochs=250,\n",
    "                                  save=\"model_state_dict.pth\")\n",
    "        model_output.append((losses, parameter_mag))\n",
    "        print(\"Finished training with profiling.\")\n",
    "\n",
    "\n",
    "    # Verify that the log directory is populated\n",
    "    if os.listdir(log_dir):\n",
    "        print(f\"Log files generated in {log_dir}\")\n",
    "    else:\n",
    "        print(f\"No log files found in {log_dir}\")\n",
    "    \n",
    "\n",
    "    print(\"Storing model state...\")\n",
    "    torch.save(model.state_dict(), f\"model_{i}_state_dict.pth\")\n",
    "    print(\"Model state stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for losses, parameter_mag in model_output:    \n",
    "    print(\"Plotting losses...\")\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Plotting parameter magnitudes...\")\n",
    "    plt.figure()\n",
    "    for key in parameter_mag:\n",
    "        plt.plot(parameter_mag[key], label=key)\n",
    "    \n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Parameter Magnitude\")\n",
    "    # plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HXCGX0Hf2h_E",
    "4F7A7ubK2h_H"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
