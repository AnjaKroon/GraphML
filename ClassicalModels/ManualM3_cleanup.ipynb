{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from gtda.graphs import KNeighborsGraph\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.join(os.path.realpath('.'), '..'))\n",
    "from preprocessor_final_data import Preprocessor\n",
    "from preprocessor_final_data import draw_network\n",
    "from preprocessor_final_data import get_adj_from_plot\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import Model3\n",
    "reload(Model3)\n",
    "from Model3 import GraphConvolutionalNetwork\n",
    "from Model3 import KroneckerDataset\n",
    "from torch.utils.data import DataLoader, Subset, random_split, SequentialSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gathering data...\")\n",
    "flow_dataset = \"../data/daily_county2county_2019_01_01.csv\"\n",
    "epi_dataset = \"../data_epi/epidemiology.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WITH THE NEW PREPROCESSOR FILE (PREPROCESSOR_FINAL_DATA.PY)\n",
    "locations_data = \"../final_data/locations_data_unique.npy\"\n",
    "epi_dataset = \"../final_data/X_normalized.npy\"\n",
    "\n",
    "# GRAPH CONVOLUTIONAL NETWORK BASED ON KRONECKER GRAPH\n",
    "import Model3\n",
    "reload(Model3)\n",
    "from Model3 import KroneckerDataset\n",
    "\n",
    "# Define the model parameters\n",
    "desired_num_params = 2000\n",
    "input_horizon = 7   # test now with smaller input horizon\n",
    "prediction_horizon = 1    # test now with smaller prediction horizon\n",
    "\n",
    "data = KroneckerDataset(Preprocessor(flow_dataset, epi_dataset, locations_data, plottable=True), input_horizon, prediction_horizon)\n",
    "\n",
    "# Created using indices from 0 to train_size.\n",
    "train_dataset = Subset(data, range(0, math.floor(len(data) * 0.8)))\n",
    "\n",
    "# Created using indices from train_size to train_size + test_size.\n",
    "test_dataset = Subset(data, range(math.floor(len(data) * 0.8), len(data)))\n",
    "\n",
    "# train_indices, test_indices = random_split(data, [0.8, 0.2])\n",
    "\n",
    "# # generate subset based on indices\n",
    "# train_split = Subset(data, train_indices)\n",
    "# test_split = Subset(data, test_indices)\n",
    "\n",
    "#train_sampler = SequentialSampler(data_source=train_dataset)\n",
    "#test_sampler = SequentialSampler(data_source=test_dataset)\n",
    "\n",
    "# # create batches\n",
    "train_batches = DataLoader(train_dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "test_batches = DataLoader(test_dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "#next(iter(train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model3\n",
    "reload(Model3)\n",
    "from Model3 import GraphConvolutionalNetwork\n",
    "\n",
    "#  Instantiate the model\n",
    "model = GraphConvolutionalNetwork(desired_num_params, input_horizon, prediction_horizon, data.num_nodes)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters:\", num_params)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "num_epochs = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# shuffle the training data randomly\n",
    "#random.shuffle(model.training_data)\n",
    "#random.shuffle(model.testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for batch in train_batches:\n",
    "        output = model(batch) # needs to have shape [num_nodes_pred, num_features]\n",
    "        \n",
    "        loss = model.getLoss(output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    for data in model.testing_data:\n",
    "        output = model(data) \n",
    "\n",
    "        loss = model.getLoss(output)\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(model.testing_data)\n",
    "\n",
    "# Compute metrics\n",
    "print(f'Test Loss: {test_loss:.8f}')\n",
    "print(model.target_graph_signal_matrix[:, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the united states and have these values as the nodes\n",
    "\n",
    "# get a list of the key values in train_graph_sig\n",
    "geoid_list_train = list(model.train_graph_sig.keys())\n",
    "target_graph_signal = model.testing_data[-1][2]\n",
    "geoid_list_target = list(target_graph_signal.keys())\n",
    "\n",
    "# make a dictionary where key is geoid_list entry and value is out entry\n",
    "train_dict = {geoid_list_train[i]: output[i, 2].item() for i in range(len(output))}\n",
    "\n",
    "target_dict = {i: target_graph_signal[i]['cumulative_confirmed'] for i in geoid_list_target}\n",
    "\n",
    "# need to get the geographical information on where to put these nodes\n",
    "# get the geographical information from the preprocessor, 'geoid_o', 'lat_o', 'lng_o' for all the geoids in train_dict\n",
    "#print(graph_kronecker_whole_df)\n",
    "\n",
    "# for each geoid_o which is a key in train_dict, get the lat_o and lng_o from the graph_kronecker_whole_df\n",
    "# then plot the united states and put the values of train_dict as the node values (new_confirmed)\n",
    "# then compare with the target_dict values\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# create model output plot\n",
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with attributes\n",
    "geoid_o = list(train_dict.keys())\n",
    "print(model.graph_kronecker_whole_df[model.graph_kronecker_whole_df['geoid_o'] == list(train_dict.keys())[0]]['lat_o'].values[0])\n",
    "lat_o = [model.graph_kronecker_whole_df[model.graph_kronecker_whole_df['geoid_o'] == key]['lat_o'].values[0] for key in train_dict.keys()]\n",
    "lng_o = [model.graph_kronecker_whole_df[model.graph_kronecker_whole_df['geoid_o'] == key]['lng_o'].values[0] for key in train_dict.keys()]\n",
    "\n",
    "\n",
    "# cumulative_confirmed = [train_dict[key] for key in train_dict.keys()] # train_dict[key] will return a dictionary not a value\n",
    "\n",
    "cumulative_confirmed = []\n",
    "# pull column 3 from graph_signal_matrix as cumulative_confirmed\n",
    "for i in range(model.graph_signal_matrix.shape[0]):\n",
    "    cumulative_confirmed.append(model.graph_signal_matrix[i, 2])\n",
    "\n",
    "\n",
    "for i in range(len(geoid_o)):\n",
    "    G.add_node(geoid_o[i], cumulative_confirmed=cumulative_confirmed[i], lat=lat_o[i], lng=lng_o[i])\n",
    "\n",
    "# Get node positions\n",
    "pos = {node: (G.nodes[node]['lng'], G.nodes[node]['lat']) for node in G.nodes}\n",
    "\n",
    "# Get node values\n",
    "node_values = [G.nodes[node]['cumulative_confirmed'] for node in G.nodes]\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(20, 8))\n",
    "nx.draw_networkx(G, pos, node_color=node_values, cmap='viridis', node_size=node_values, alpha=0.8, with_labels=False)\n",
    "# plt.colorbar(label='New Confirmed Cases')\n",
    "plt.title('Graph of COVID-19 Cases: MODEL OUTPUT')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "########## create Ground truth plot\n",
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with attributes\n",
    "geoid_o = list(train_dict.keys())\n",
    "lat_o = [model.graph_kronecker_whole_df[model.graph_kronecker_whole_df['geoid_o'] == key]['lat_o'].values[0] for key in train_dict.keys()]\n",
    "lng_o = [model.graph_kronecker_whole_df[model.graph_kronecker_whole_df['geoid_o'] == key]['lng_o'].values[0] for key in train_dict.keys()]\n",
    "\n",
    "\n",
    "# cumulative_confirmed = [train_dict[key] for key in train_dict.keys()] # train_dict[key] will return a dictionary not a value\n",
    "\n",
    "cumulative_confirmed = []\n",
    "# pull column 3 from graph_signal_matrix as cumulative_confirmed\n",
    "for i in range(model.target_graph_signal_matrix.shape[0]):\n",
    "    cumulative_confirmed.append(model.target_graph_signal_matrix[i, 2])\n",
    "\n",
    "for i in range(len(geoid_o)):\n",
    "    G.add_node(geoid_o[i], cumulative_confirmed=cumulative_confirmed[i], lat=lat_o[i], lng=lng_o[i])\n",
    "\n",
    "# Get node positions\n",
    "pos = {node: (G.nodes[node]['lng'], G.nodes[node]['lat']) for node in G.nodes}\n",
    "\n",
    "# Get node values\n",
    "node_values = [G.nodes[node]['cumulative_confirmed'] for node in G.nodes]\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(20, 8))\n",
    "nx.draw_networkx(G, pos, node_color=node_values, cmap='viridis', node_size=node_values, alpha=0.8, with_labels=False)\n",
    "# plt.colorbar(label='New Confirmed Cases')\n",
    "plt.title('Graph of COVID-19 Cases: Ground Truth')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
